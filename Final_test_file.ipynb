{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing emotion cause analysis using Bert model and adding additional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\vivek\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\vivek\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# Imports for most of the notebook\n",
    "import torch\n",
    "from transformers import BertModel\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Dict, List\n",
    "import random\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Opening JSON file\n",
    "f = open('.\\Data\\\\text\\Subtask_1_train.json')\n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separate labels and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo: find x_data and y_label\n",
    "x_data = []\n",
    "y_cause_labels = []\n",
    "y_emotion_labels = []\n",
    "\n",
    "# Iterate through each conversation in the dataset\n",
    "for conv in data:\n",
    "    # Extract conversation, emotion-cause pairs, and emotion labels\n",
    "    conversation = conv['conversation']\n",
    "    emotion_cause_pairs = conv['emotion-cause_pairs']\n",
    "    \n",
    "    # Extract emotion labels from each utterance in the conversation\n",
    "    emotion_labels = [utterance['emotion'] for utterance in conversation]\n",
    "\n",
    "    # Append to the respective lists\n",
    "    x_data.append(conversation)\n",
    "    y_cause_labels.extend(emotion_cause_pairs)\n",
    "    y_emotion_labels.append(emotion_labels) # figure out if its append or extend\n",
    "\n",
    "# Print the extracted data\n",
    "# print(\"Conversations:\")\n",
    "# for conv in x_data:\n",
    "#     print(conv)\n",
    "\n",
    "# print(\"\\nEmotion-Cause Pairs:\")\n",
    "# for pair in y_cause_labels:\n",
    "#     print(pair)\n",
    "\n",
    "# print(\"\\nEmotion Labels:\")\n",
    "# print(y_emotion_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the label formart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo: change ['17_anger', '16_we could throw you both in'] --> ['17_anger', '16'] and making sure labels is list[list[labels for each conversation]]. confirm if labels needs to be in this formart list[list[labels for each conversation]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1099\n",
      "Development set size: 275\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_conv, dev_conv = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "#todo: with above x_data and y_label get x_train, y_ label, x_dev and y_dev\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and development sets\n",
    "x_train, x_dev, y_train, y_dev = train_test_split(x_data, y_emotion_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the sizes of the sets\n",
    "print(\"Training set size:\", len(x_train))\n",
    "print(\"Development set size:\", len(x_dev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this for now\n",
    "\n",
    "# class BatchTokenizer:\n",
    "#     \"\"\"Tokenizes and pads a batch of input sentences.\"\"\"\n",
    "\n",
    "#     def __init__(self, model_name=\"bert-base-uncased\"):\n",
    "#         \"\"\"Initializes the tokenizer\n",
    "\n",
    "#         Args:\n",
    "#             pad_symbol (Optional[str], optional): The symbol for a pad. Defaults to \"<P>\".\n",
    "#         \"\"\"\n",
    "#         self.conv_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#         self.model_name = model_name\n",
    "    \n",
    "#     def get_sep_token(self,):\n",
    "#         return self.conv_tokenizer.sep_token\n",
    "    \n",
    "#     def __call__(self, conv_batch: List[dict]) -> List[dict[str]]:\n",
    "#         \"\"\"Uses the huggingface tokenizer to tokenize and pad a batch.\n",
    "\n",
    "#         We return a dictionary of tensors per the huggingface model specification.\n",
    "\n",
    "#         Args:\n",
    "#             batch (List[str]): A List of sentence strings\n",
    "\n",
    "#         Returns:\n",
    "#             Dict: The dictionary of token specifications provided by HuggingFace\n",
    "#         \"\"\"\n",
    "#         # The HF tokenizer will PAD for us, and additionally combine \n",
    "#         # The two sentences deimited by the [SEP] token.\n",
    "#         # combined_texts = [f\"{utterance['speaker']}: {utterance['text']}\" for utterance in conv_batch[\"conversation\"]]\n",
    "#         # print(combined_texts)\n",
    "        \n",
    "#         # print(conv_batch)\n",
    "#         combined_single_texts=[]\n",
    "#         batch_texts=[]\n",
    "#         for conv in conv_batch:\n",
    "#             #print(conv)\n",
    "#             combined_single_texts=[]\n",
    "#             for utterance in conv:\n",
    "#                 combined_single_texts.append(f\"{utterance['speaker']}: {utterance['text']}\")\n",
    "#             batch_texts.append(combined_single_texts)\n",
    "#         #print(batch_texts)\n",
    "#         encoded=[]\n",
    "#         for batch in batch_texts:\n",
    "#             enc = self.conv_tokenizer(\n",
    "#                 batch,\n",
    "#                 padding=True,\n",
    "#                 return_token_type_ids=False,\n",
    "#                 return_tensors='pt'\n",
    "#             )\n",
    "#             encoded.append(enc)\n",
    "#         #print(encoded)\n",
    "#         return enc\n",
    "    \n",
    "\n",
    "# HERE IS AN EXAMPLE OF HOW TO USE THE BATCH TOKENIZER\n",
    "# tokenizer = BatchTokenizer()\n",
    "# x = tokenizer(x_train[0:10])\n",
    "#print(x)\n",
    "#tokenizer.conv_tokenizer.batch_decode(x[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Texts for Conversation 1: ['[CLS] monica : ow! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] richard : really?! well, it is just like everyone else apartment. it is got rooms, walls, and ceilings. [SEP]', \"[CLS] richard's date : well, i just wanted to see where you lived. now, give me the tour. [SEP] [PAD] [PAD]\", '[CLS] monica : oh my god! oh my god! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] richard : ah well, this is the living room. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] richard : all right. this is the kitchen. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] richard : the bedroom. well it is pretty much your typical... bedroom. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', \"[CLS] richard's date : we are still on this side of the door. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", \"[CLS] richard's date : yeah, but i did not get to see it. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", '[CLS] richard : oh shoot! maybe next time. thanks for a lovely evening. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] monica : so um, who was she? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] richard : oh, that was the blind date that i told you about, she called and switched it to today. [SEP] [PAD] [PAD]', '[CLS] monica : did you like her? and i am just asking as a friend, because i am totally fine with this. [SEP] [PAD]', '[CLS] richard : well, you seem fine. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n"
     ]
    }
   ],
   "source": [
    "# from typing import List, Dict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class BatchTokenizer:\n",
    "    \"\"\"Tokenizes and pads a batch of input sentences.\"\"\"\n",
    "\n",
    "    def __init__(self, model_name=\"bert-base-uncased\"):\n",
    "        \"\"\"Initializes the tokenizer.\n",
    "\n",
    "        Args:\n",
    "            model_name (str, optional): Pretrained model name. Defaults to \"bert-base-uncased\".\n",
    "        \"\"\"\n",
    "        self.conv_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model_name = model_name\n",
    "    \n",
    "    def get_sep_token(self):\n",
    "        return self.conv_tokenizer.sep_token\n",
    "    \n",
    "    def __call__(self, conv_batch: List[Dict[str, List[Dict[str, str]]]]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Uses the Hugging Face tokenizer to tokenize and pad a batch.\n",
    "\n",
    "        Args:\n",
    "            conv_batch (List[Dict[str, List[Dict[str, str]]]]): A list of conversations.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, torch.Tensor]: The dictionary of token specifications provided by Hugging Face.\n",
    "        \"\"\"\n",
    "        # The HF tokenizer will PAD for us, and additionally combine \n",
    "        # the sentences delimited by the [SEP] token.\n",
    "        \n",
    "        tokenized_conversations = []\n",
    "\n",
    "        for conv in conv_batch:\n",
    "            conv_tokens = self.conv_tokenizer(\n",
    "                [f\"{utterance['speaker']}: {utterance['text']}\" for utterance in conv],\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                return_token_type_ids=False,\n",
    "                max_length=512  \n",
    "            )\n",
    "            tokenized_conversations.append(conv_tokens)\n",
    "\n",
    "        return tokenized_conversations\n",
    "\n",
    "# Example of how to use the batch tokenizer\n",
    "tokenizer = BatchTokenizer()\n",
    "batch_encodings = tokenizer([x_train[0], x_train[1]])  # Pass a batch of conversations\n",
    "#print(batch_encodings)\n",
    "decoded_texts = tokenizer.conv_tokenizer.batch_decode(batch_encodings[1][\"input_ids\"])\n",
    "print(\"Decoded Texts for Conversation 1:\", decoded_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making batched of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        #print(lst[i:i + n])\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "batch_size = 8\n",
    "        \n",
    "# Notice that since we use huggingface, we tokenize and\n",
    "# encode in all at once!\n",
    "tokenizer = BatchTokenizer()\n",
    "train_input_batches_temp = [b for b in chunk(x_train, batch_size)]\n",
    "#print(train_input_batches)\n",
    "# Tokenize + encode\n",
    "train_input_batches = [tokenizer(batch) for batch in train_input_batches_temp]\n",
    "\n",
    "dev_input_batches = [b for b in chunk(x_dev, batch_size)]\n",
    "\n",
    "# Tokenize + encode\n",
    "dev_input_batches = [tokenizer(batch) for batch in dev_input_batches]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dev_input_batches[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: batch and encode the following needed for model training  x_train, y_ label, x_dev and y_dev\n",
    "\n",
    "def encode_labels(batch_labels: List[List[str]], label_map: Dict[str, int]) -> torch.FloatTensor:\n",
    "    \"\"\"Turns the batch of labels into a tensor using the provided label map\n",
    "\n",
    "    Args:\n",
    "        batch_labels (List[List[str]]): List of lists of labels in the batch\n",
    "        label_map (Dict[str, int]): Dictionary mapping label strings to integers\n",
    "\n",
    "    Returns:\n",
    "        torch.FloatTensor: Tensor of all labels in the batch\n",
    "    \"\"\"\n",
    "    # Encode each label in the batch using the label map\n",
    "    encoded_labels = [torch.tensor([label_map[label] for label in labels], dtype=torch.float32) for labels in batch_labels]\n",
    "    #print(encoded_labels)\n",
    "\n",
    "    # Convert the list of lists to a tensor\n",
    "  \n",
    "\n",
    "    return encoded_labels\n",
    "# unique emotions ['anger' 'disgust' 'fear' 'joy' 'neutral' 'sadness' 'surprise']\n",
    "encode_label_map = {'neutral': 0, 'surprise': 1, 'anger': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'fear': 6}\n",
    "\n",
    "train_label_batches = [b for b in chunk(y_emotion_labels, batch_size)]\n",
    "# print(train_label_batches[0])\n",
    "# for batch in train_label_batches:\n",
    "#     print(batch)\n",
    "train_label_batches = [encode_labels(batch, encode_label_map) for batch in train_label_batches]\n",
    "\n",
    "dev_batch_labels = [b for b in chunk(y_dev, batch_size)]\n",
    "dev_batch_labels = [encode_labels(batch, encode_label_map) for batch in dev_batch_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sum as t_sum\n",
    "from numpy import logical_and\n",
    "\n",
    "\n",
    "def precision(predicted_labels, true_labels, which_label=1):\n",
    "    \"\"\"\n",
    "    Precision is True Positives / All Positives Predictions\n",
    "    \"\"\"\n",
    "    pred_which = np.array([pred == which_label for pred in predicted_labels])\n",
    "    true_which = np.array([lab == which_label for lab in true_labels])\n",
    "    denominator = t_sum(pred_which)\n",
    "    if denominator:\n",
    "        return t_sum(logical_and(pred_which, true_which))/denominator\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def recall(predicted_labels, true_labels, which_label=1):\n",
    "    \"\"\"\n",
    "    Recall is True Positives / All Positive Labels\n",
    "    \"\"\"\n",
    "    pred_which = np.array([pred == which_label for pred in predicted_labels])\n",
    "    true_which = np.array([lab == which_label for lab in true_labels])\n",
    "    denominator = t_sum(true_which)\n",
    "    if denominator:\n",
    "        return t_sum(logical_and(pred_which, true_which))/denominator\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def f1_score(\n",
    "    predicted_labels: List[int],\n",
    "    true_labels: List[int],\n",
    "    which_label: int\n",
    "):\n",
    "    \"\"\"\n",
    "    F1 score is the harmonic mean of precision and recall\n",
    "    \"\"\"\n",
    "    P = precision(predicted_labels, true_labels, which_label=which_label)\n",
    "    R = recall(predicted_labels, true_labels, which_label=which_label)\n",
    "    \n",
    "    if P and R:\n",
    "        return 2*P*R/(P+R)\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def macro_f1(\n",
    "    predicted_labels: List[int],\n",
    "    true_labels: List[int],\n",
    "    possible_labels: List[int],\n",
    "    label_map=None\n",
    "):\n",
    "    converted_prediction = [label_map[int(x)] for x in predicted_labels] if label_map else predicted_labels\n",
    "    scores = [f1_score(converted_prediction, true_labels, l) for l in possible_labels]\n",
    "    # Macro, so we take the uniform avg.\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for emotion classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier(torch.nn.Module):\n",
    "    def __init__(self, output_size: int, hidden_size: int, model_name='prajjwal1/bert-small'):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Initialize BERT, which we use instead of a single embedding layer.\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        \n",
    "        # [OPTIONAL]: Updating all BERT parameters can be slow and memory intensive. \n",
    "        # Freeze them if training is too slow. Notice that the learning\n",
    "        # rate should probably be smaller in this case.\n",
    "        # Uncommenting out the below 2 lines means only our classification layer will be updated.\n",
    "        \n",
    "        # for param in self.bert.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        \n",
    "        self.bert_hidden_dimension = self.bert.config.hidden_size\n",
    "        \n",
    "        # DONE: Add an extra hidden layer in the classifier, projecting\n",
    "        #      from the BERT hidden dimension to hidden size. Hint: torch.nn.Linear()\n",
    "        \n",
    "        self.hidden_layer = torch.nn.Linear(self.bert_hidden_dimension, self.hidden_size)\n",
    "        \n",
    "        # DONE: Add a relu nonlinearity to be used in the forward method\n",
    "        #      https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html\n",
    "        \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.classifier = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=2)\n",
    "    \n",
    "    def encode_text(\n",
    "        self,\n",
    "        symbols: Dict\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Encode the (batch of) sequence(s) of token symbols BERT.\n",
    "            Then, get CLS represenation.\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: CLS token embedding\n",
    "        \"\"\"\n",
    "        # Get the contextualized embedding for each input symbol\n",
    "        encoded_sequence = self.bert(**symbols)\n",
    "        \n",
    "        # Extract the [CLS] token representation\n",
    "        cls_token_embedding = encoded_sequence.last_hidden_state[:, 0, :]  # Extract [CLS] token\n",
    "        \n",
    "        return cls_token_embedding.unsqueeze(1)  # Reshape to batch_size x 1 x bert_hidden_dimension\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        symbols: Dict,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: _description_\n",
    "        \"\"\"\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        # Directly get BERT output (including [CLS] token) from input symbols\n",
    "        encoded_sents = self.encode_text(symbols)\n",
    "        output = self.hidden_layer(encoded_sents)\n",
    "        # Extract the [CLS] token representation\n",
    "        #cls_token_embedding = encoded_sequence.last_hidden_state[:, 0, :]  # Assuming [CLS] is at index 0\n",
    "        \n",
    "        # Pass through hidden layer and activation\n",
    "        #output = self.hidden_layer(cls_token_embedding.unsqueeze(1))\n",
    "        output = self.hidden_layer(output)\n",
    "        output = self.relu(output)\n",
    "        \n",
    "        # Classification layer\n",
    "        output = self.classifier(output)\n",
    "        return self.log_softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For making predictions at test time\n",
    "def predict(model: torch.nn.Module, sents: torch.Tensor) -> List:\n",
    "    logits = model(sents)\n",
    "    return list(torch.argmax(logits, axis=2).squeeze().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(\n",
    "    num_epochs,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    dev_sents,\n",
    "    dev_labels,\n",
    "    optimizer,\n",
    "    model,\n",
    "):\n",
    "    print(\"Training...\")\n",
    "    #loss_func = torch.nn.NLLLoss()\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    \n",
    "    \n",
    "    batches = list(zip(train_features, train_labels))\n",
    "    #print(batches)\n",
    "    random.shuffle(batches)\n",
    "    # Convert your data into PyTorch tensors\n",
    "    #train_features_tensor = torch.tensor(train_features)\n",
    "    #train_labels_tensor = torch.tensor(train_labels)\n",
    "    \n",
    "    # Create a TensorDataset from your features and labels\n",
    "    #train_dataset = TensorDataset(train_features_tensor, train_labels_tensor)\n",
    "    \n",
    "    # Create a DataLoader to handle batching and shuffling\n",
    "    #train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        losses = []\n",
    "        \n",
    "        for features, labels in tqdm(batches):\n",
    "            # print(features, labels)\n",
    "            # Empty the dynamic computation graph\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(features).squeeze(1)\n",
    "\n",
    "            # loss = loss_func(preds, labels.to(device))\n",
    "            loss = loss_func(preds, labels)\n",
    "            # Backpropogate the loss through our model\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        print(f\"epoch {i}, loss: {sum(losses)/len(losses)}\")\n",
    "        # Estimate the f1 score for the development set\n",
    "        print(\"Evaluating dev...\")\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        for sents, labels in tqdm(zip(dev_sents, dev_labels), total=len(dev_sents)):\n",
    "            # pred = predict(model, sents).cpu()\n",
    "            pred = predict(model, sents)\n",
    "            all_preds.extend(pred)\n",
    "            # all_labels.extend(list(labels.cpu().numpy()))\n",
    "            all_labels.extend(list(labels.numpy()))\n",
    "\n",
    "        x = np.array(all_labels)\n",
    "        unique_possible_labels = list(np.unique(x))\n",
    "        dev_f1 = macro_f1(all_preds, all_labels, unique_possible_labels)\n",
    "        # dev_f1 = macro_f1_score(all_preds, all_labels, list(train_labels))\n",
    "        print(f\"Dev F1 {dev_f1}\")\n",
    "        \n",
    "    # Return the trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb068e24030e4dfbbe31ccd5c095c6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(30522, 512, padding_idx=0)\n    (position_embeddings): Embedding(512, 512)\n    (token_type_embeddings): Embedding(2, 512)\n    (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=512, out_features=512, bias=True)\n            (key): Linear(in_features=512, out_features=512, bias=True)\n            (value): Linear(in_features=512, out_features=512, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=512, out_features=512, bias=True)\n            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=512, out_features=2048, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=2048, out_features=512, bias=True)\n          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=512, out_features=512, bias=True)\n            (key): Linear(in_features=512, out_features=512, bias=True)\n            (value): Linear(in_features=512, out_features=512, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=512, out_features=512, bias=True)\n            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=512, out_features=2048, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=2048, out_features=512, bias=True)\n          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=512, out_features=512, bias=True)\n            (key): Linear(in_features=512, out_features=512, bias=True)\n            (value): Linear(in_features=512, out_features=512, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=512, out_features=512, bias=True)\n            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=512, out_features=2048, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=2048, out_features=512, bias=True)\n          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=512, out_features=512, bias=True)\n            (key): Linear(in_features=512, out_features=512, bias=True)\n            (value): Linear(in_features=512, out_features=512, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=512, out_features=512, bias=True)\n            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=512, out_features=2048, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=2048, out_features=512, bias=True)\n          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=512, out_features=512, bias=True)\n    (activation): Tanh()\n  )\n) argument after ** must be a mapping, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22624\\2459157536.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m training_loop(\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mtrain_input_batches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22624\\2649827337.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[1;34m(num_epochs, train_features, train_labels, dev_sents, dev_labels, optimizer, model)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;31m# Empty the dynamic computation graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;31m# loss = loss_func(preds, labels.to(device))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22624\\3158195478.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, symbols)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;34m\"\"\"Forward pass.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;31m# Directly get BERT output (including [CLS] token) from input symbols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mencoded_sents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_sents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# Extract the [CLS] token representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22624\\3158195478.py\u001b[0m in \u001b[0;36mencode_text\u001b[1;34m(self, symbols)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \"\"\"\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m# Get the contextualized embedding for each input symbol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mencoded_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m# Extract the [CLS] token representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(30522, 512, padding_idx=0)\n    (position_embeddings): Embedding(512, 512)\n    (token_type_embeddings): Embedding(2, 512)\n    (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=512, out_features=512, bias=True)\n            (key): Linear(in_features=512, out_features=512, bias=True)\n            (value): Linear(in_features=512, out_features=512, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=512, out_features=512, bias=True)\n            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=512, out_features=2048, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=2048, out_features=512, bias=True)\n          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=512, out_features=512, bias=True)\n            (key): Linear(in_features=512, out_features=512, bias=True)\n            (value): Linear(in_features=512, out_features=512, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=512, out_features=512, bias=True)\n            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=512, out_features=2048, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=2048, out_features=512, bias=True)\n          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=512, out_features=512, bias=True)\n            (key): Linear(in_features=512, out_features=512, bias=True)\n            (value): Linear(in_features=512, out_features=512, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=512, out_features=512, bias=True)\n            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=512, out_features=2048, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=2048, out_features=512, bias=True)\n          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=512, out_features=512, bias=True)\n            (key): Linear(in_features=512, out_features=512, bias=True)\n            (value): Linear(in_features=512, out_features=512, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=512, out_features=512, bias=True)\n            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=512, out_features=2048, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=2048, out_features=512, bias=True)\n          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=512, out_features=512, bias=True)\n    (activation): Tanh()\n  )\n) argument after ** must be a mapping, not list"
     ]
    }
   ],
   "source": [
    "# You can increase epochs if need be\n",
    "epochs = 20\n",
    "\n",
    "# TODO: Find a good learning rate and hidden size\n",
    "LR = 0.01\n",
    "hidden_size = 10\n",
    "\n",
    "#possible_labels = set(train_labels)\n",
    "model = EmotionClassifier(output_size=7, hidden_size=hidden_size)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), LR)\n",
    "\n",
    "\n",
    "training_loop(\n",
    "    epochs,\n",
    "    train_input_batches,\n",
    "    train_label_batches,\n",
    "    dev_input_batches,\n",
    "    dev_batch_labels,\n",
    "    optimizer,\n",
    "    model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
