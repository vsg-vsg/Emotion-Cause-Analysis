{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading library's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the dataset into Train and Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load a pre-trained model for emotion detection\n",
    "# Note: Choose an appropriate model from HuggingFace's model hub\n",
    "#emotion_detector = pipeline('sentiment-analysis', model=\"distilbert-base-uncased\")\n",
    "#emotion_detector = pipeline('sentiment-analysis', model='j-hartmann/emotion-english-distilroberta-base')\n",
    "emotion_detector = pipeline('sentiment-analysis', model='roberta-base')\n",
    "\n",
    "# Sample data (replace this with your actual dataset)\n",
    "f = open('.\\Data\\\\text\\Subtask_1_train.json')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "conversation_data = json.load(f)\n",
    "\n",
    "# Function to predict emotions for each utterance in the conversation\n",
    "def predict_emotions(conversation):\n",
    "    for utterance in conversation:\n",
    "        #print(utterance)\n",
    "        # Predict the emotion using the pre-trained model\n",
    "        results = emotion_detector(utterance[\"text\"])\n",
    "        # Update the emotion for the utterance with the predicted one\n",
    "        # Note: The model might return labels different than the dataset's original labels\n",
    "        # You may need to map model labels to your dataset's labels\n",
    "        predicted_emotion = results[0]['label']\n",
    "        utterance[\"predicted_emotion\"] = predicted_emotion.lower()\n",
    "\n",
    "# Predict emotions for the conversation\n",
    "\n",
    "predict_emotions(conversation_data[0][\"conversation\"])\n",
    "\n",
    "# Now conversation_data contains predicted emotions for each utterance\n",
    "print(conversation_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195a3b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acuracy_for_conversation(conv_data):\n",
    "    utterance_list = conv_data['conversation']\n",
    "\n",
    "    # Step 1: Calculate the total number of emotion-utterance pairs\n",
    "    total_pairs = len(utterance_list)\n",
    "\n",
    "    # Step 2: Calculate the number of emotion-utterance pairs where \"emotion\" and \"predicted_emotion\" are equal\n",
    "    equal_pairs = sum(1 for utterance in utterance_list if utterance['emotion'] == utterance['predicted_emotion'])\n",
    "\n",
    "    # Step 3: Calculate the ratio of equal emotions to the total number of emotion-utterance pairs\n",
    "    return equal_pairs / total_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9db69f4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'disgust' 'fear' 'joy' 'neutral' 'sadness' 'surprise']\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "accuracy_avg = []\n",
    "emotion_types = []\n",
    "\n",
    "for conversation_id in range(len(conversation_data)):\n",
    "    predict_emotions(conversation_data[conversation_id][\"conversation\"])\n",
    "    for utterance in conversation_data[conversation_id][\"conversation\"]:\n",
    "        emotion_types.append(utterance[\"emotion\"])\n",
    "    accuracy_avg.append(acuracy_for_conversation(conversation_data[conversation_id]))\n",
    "\n",
    "print(np.unique(np.array(emotion_types)))\n",
    "print(np.mean(accuracy_avg))\n",
    "# Now conversation_data contains predicted emotions for each utterance\n",
    "#print(acuracy_for_conversation(conversation_data[0]), acuracy_for_conversation(conversation_data[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9baecf",
   "metadata": {},
   "source": [
    "Available unique emotions: ['anger' 'disgust' 'fear' 'joy' 'neutral' 'sadness' 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c8f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
